{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prereq\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('fashion-mnist_train.csv')\n",
    "cross = pd.read_csv('fashion-mnist_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_and_cross = [train, cross]\n",
    "dataset = pd.concat(concat_train_and_cross) # create 1 single frame from cross and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: normalize\n",
    "\n",
    "def normalize_df(df):\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetX = normalize_df(dataset.iloc[:, 1:])\n",
    "datasetX_augment_negativ = normalize_df(255 - dataset.iloc[:, 1:])\n",
    "datasetX_augment_half_channel = normalize_df(dataset.iloc[:, 1:] / 2)\n",
    "datasetX_augment_half_channel_negativ = normalize_df((255 - dataset.iloc[:, 1:]) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetY = dataset.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000, 1) (70000, 784) (70000, 784) (70000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(datasetX.shape, datasetY.shape,datasetX_augment_negativ.shape,datasetX_augment_half_channel.shape,datasetX_augment_half_channel_negativ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, X_c, X_t = split(datasetX)\n",
    "# Y, Y_c, Y_t = split(datasetY)\n",
    "\n",
    "# nX, nX_c, nX_t = split(datasetX_augment_negativ)\n",
    "# hX, hX_c, hX_t = split(datasetX_augment_half_channel)\n",
    "\n",
    "X = datasetX.sample(frac=0.99,random_state=200) # split in 99% and 1%, 99% for train and 1% for dev and test\n",
    "Xcross_and_test = datasetX.drop(X.index)\n",
    "X_c = Xcross_and_test.sample(frac=0.5,random_state=200)\n",
    "X_t = Xcross_and_test.drop(X_c.index)\n",
    "\n",
    "\n",
    "Y = datasetY.iloc[X.index,:] # split in 99% and 1%, 99% for train and 1% for dev and test\n",
    "Y_c = datasetY.iloc[X_c.index,:]\n",
    "Y_t = datasetY.iloc[X_t.index,:]\n",
    "\n",
    "\n",
    "nX = datasetX_augment_negativ.iloc[X.index,:] # split in 99% and 1%, 99% for train and 1% for dev and test\n",
    "nX_c = datasetX_augment_negativ.iloc[X_c.index,:]\n",
    "nX_t = datasetX_augment_negativ.iloc[X_t.index,:]\n",
    "\n",
    "\n",
    "hX = datasetX_augment_half_channel.iloc[X.index,:] # split in 99% and 1%, 99% for train and 1% for dev and test\n",
    "hX_c = datasetX_augment_half_channel.iloc[X_c.index,:]\n",
    "hX_t = datasetX_augment_half_channel.iloc[X_t.index,:]\n",
    "\n",
    "\n",
    "nhX = datasetX_augment_half_channel_negativ.iloc[X.index,:] # split in 99% and 1%, 99% for train and 1% for dev and test\n",
    "nhX_c = datasetX_augment_half_channel_negativ.iloc[X_c.index,:]\n",
    "nhX_t = datasetX_augment_half_channel_negativ.iloc[X_t.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69300, 1) (350, 1) (350, 1) (70000, 784)\n",
      "(69300, 784) (350, 784) (350, 784) (70000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape, Y_c.shape, Y_t.shape, datasetX.shape)\n",
    "print(X.shape, X_c.shape, X_t.shape, datasetY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label0 Cross set: 31 Test set:  32\n",
      "Label1 Cross set: 37 Test set:  41\n",
      "Label2 Cross set: 29 Test set:  33\n",
      "Label3 Cross set: 31 Test set:  39\n",
      "Label4 Cross set: 38 Test set:  31\n",
      "Label5 Cross set: 35 Test set:  29\n",
      "Label6 Cross set: 35 Test set:  38\n",
      "Label7 Cross set: 36 Test set:  36\n",
      "Label8 Cross set: 44 Test set:  42\n",
      "Label9 Cross set: 34 Test set:  29\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see if the data is relativ. uniform distrib. over the colum label\n",
    "for i in range(10):\n",
    "    print('Label'+str(i),'Cross set:',len(np.where(Y_c['label'] == i)[0]), 'Test set: ', len(np.where(Y_t['label'] == i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([X, nX, hX, nhX])\n",
    "y = pd.concat([Y, Y, Y, Y])\n",
    "\n",
    "x_c = pd.concat([X_c, nX_c, hX_c, nhX_c])\n",
    "y_c = pd.concat([Y_c, Y_c, Y_c, Y_c])\n",
    "\n",
    "x_t = pd.concat([X_t])\n",
    "y_t = pd.concat([Y_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('X.csv')\n",
    "y.to_csv('Y.csv')\n",
    "x_c.to_csv('X_c.csv')\n",
    "y_c.to_csv('Y_c.csv')\n",
    "x_t.to_csv('X_t.csv')\n",
    "y_t.to_csv('Y_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69300, 1) (350, 1) (350, 1) (70000, 784)\n",
      "(69300, 784) (350, 784) (350, 784) (70000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape, Y_c.shape, Y_t.shape, datasetX.shape)\n",
    "print(X.shape, X_c.shape, X_t.shape, datasetY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
